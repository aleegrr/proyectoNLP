{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ba24f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1f3d7",
   "metadata": {},
   "source": [
    "### Cargar datos, preprocesarlos y entrenar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46fc0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta sección se encarga de la carga de los datos, la aplicación de técnicas de preprocesamiento de texto esenciales\n",
    "# y el entrenamiento de un modelo de clasificación de texto utilizando el algoritmo de Regresión Logística.\n",
    "\n",
    "# Descargar recursos de NLTK si no están presentes\n",
    "# NLTK (Natural Language Toolkit) es una librería fundamental para el procesamiento de lenguaje natural en Python.\n",
    "# Este bloque asegura que los recursos necesarios para el preprocesamiento (stopwords y WordNet) estén descargados.\n",
    "try:\n",
    "    stopwords.words('english') # Intenta acceder a la lista de stopwords en inglés.\n",
    "    WordNetLemmatizer().lemmatize('running') # Intenta usar la función de lematización.\n",
    "except LookupError:\n",
    "    print(\"Descargando recursos de NLTK...\")\n",
    "    nltk.download('stopwords') # Descarga la lista de stopwords si no se encuentra.\n",
    "    nltk.download('wordnet') # Descarga el léxico WordNet si no se encuentra.\n",
    "    print(\"Recursos de NLTK descargados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1916cc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "   label                                               text\n",
      "0      0  donald trump sends out embarrassing new year‚s...\n",
      "1      0  drunk bragging trump staffer started russian c...\n",
      "2      0  sheriff david clarke becomes an internet joke ...\n",
      "3      0  trump is so obsessed he even has obama‚s name ...\n",
      "4      0  pope francis just called out donald trump duri...\n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34152 entries, 0 to 34151\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   34152 non-null  int64 \n",
      " 1   text    34152 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 533.8+ KB\n",
      "None\n",
      "\n",
      "Distribución de las etiquetas:\n",
      "label\n",
      "0    17572\n",
      "1    16580\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar y explorar los datos\n",
    "# Se utiliza la librería pandas para cargar el dataset desde un archivo CSV.\n",
    "file_path = 'data/training_data.csv' # Define la ruta al archivo de entrenamiento.\n",
    "df = pd.read_csv(file_path, header=None, names=['label', 'text'], sep='\\t')\n",
    "# El archivo se carga sin encabezado y se asignan nombres a las columnas: 'label' (la clase a predecir) y 'text' (el contenido textual).\n",
    "# La separación de los datos en el archivo es por tabulador ('\\t').\n",
    "\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(df.head()) # Muestra las primeras filas del DataFrame para inspeccionar los datos.\n",
    "print(\"\\nInformación del dataset:\")\n",
    "print(df.info()) # Proporciona un resumen conciso del DataFrame, incluyendo el tipo de datos y la cantidad de entradas no nulas.\n",
    "print(\"\\nDistribución de las etiquetas:\")\n",
    "print(df['label'].value_counts()) # Muestra la frecuencia de cada valor único en la columna 'label', lo que ayuda a entender el balance de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08b9ffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto preprocesado (ejemplo):\n",
      "                                                text  \\\n",
      "0  donald trump sends out embarrassing new year‚s...   \n",
      "1  drunk bragging trump staffer started russian c...   \n",
      "2  sheriff david clarke becomes an internet joke ...   \n",
      "3  trump is so obsessed he even has obama‚s name ...   \n",
      "4  pope francis just called out donald trump duri...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  donald trump sends embarrassing new year eve m...  \n",
      "1  drunk bragging trump staffer started russian c...  \n",
      "2  sheriff david clarke becomes internet joke thr...  \n",
      "3  trump obsessed even obamas name coded website ...  \n",
      "4  pope francis called donald trump christmas speech  \n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento del texto\n",
    "# Esta etapa es crucial para limpiar y normalizar el texto antes de alimentarlo al modelo de aprendizaje automático.\n",
    "stop_words = set(stopwords.words('english')) # Crea un conjunto de palabras comunes en inglés que se eliminarán. La conversión a conjunto mejora la eficiencia de la búsqueda.\n",
    "lemmatizer = WordNetLemmatizer() # Inicializa el lematizador, que reduce las palabras a su forma base o lema.\n",
    "\n",
    "def clean_text(text):\n",
    "    # Esta función toma un texto como entrada y aplica una serie de pasos de limpieza.\n",
    "    text = text.lower() # Convierte todo el texto a minúsculas para asegurar la uniformidad.\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Utiliza una expresión regular para eliminar cualquier carácter que no sea una letra (mayúscula o minúscula) o un espacio en blanco. Esto elimina números y signos de puntuación.\n",
    "    tokens = text.split() # Divide el texto en una lista de palabras (tokens) utilizando los espacios como delimitadores.\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words] # Aplica la lematización a cada palabra que no esté en la lista de stopwords.\n",
    "    return \" \".join(tokens) # Une los tokens limpios y lematizados de nuevo en una cadena de texto, separados por espacios.\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text) # Aplica la función clean_text a cada elemento de la columna 'text' del DataFrame, creando una nueva columna llamada 'cleaned_text' con el texto preprocesado.\n",
    "print(\"\\nTexto preprocesado (ejemplo):\")\n",
    "print(df[['text', 'cleaned_text']].head()) # Muestra las primeras filas comparando el texto original con el texto preprocesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b41c6b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño del conjunto de entrenamiento: (27321,)\n",
      "Tamaño del conjunto de prueba: (6831,)\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# Es fundamental dividir el dataset en un conjunto de entrenamiento para entrenar el modelo y un conjunto de prueba para evaluar su rendimiento en datos no vistos.\n",
    "X = df['cleaned_text'] # Define la columna 'cleaned_text' como la variable predictora (características).\n",
    "y = df['label'] # Define la columna 'label' como la variable objetivo (la clase a predecir).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# La función train_test_split divide los datos.\n",
    "# test_size=0.2 indica que el 20% de los datos se utilizará para la prueba.\n",
    "# random_state=42 asegura que la división sea la misma cada vez que se ejecuta el código, lo que es importante para la reproducibilidad.\n",
    "# stratify=y asegura que la proporción de las clases en el conjunto de prueba sea la misma que en el conjunto de datos original, lo cual es crucial para datasets desbalanceados.\n",
    "\n",
    "print(f\"\\nTamaño del conjunto de entrenamiento: {X_train.shape}\") # Muestra el número de muestras en el conjunto de entrenamiento.\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\") # Muestra el número de muestras en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f97c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma de la matriz TF-IDF para el conjunto de entrenamiento: (27321, 5000)\n",
      "Forma de la matriz TF-IDF para el conjunto de prueba: (6831, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Vectorización del texto usando TF-IDF\n",
    "# Los modelos de aprendizaje automático no pueden trabajar directamente con texto, por lo que necesitamos convertirlo en representaciones numéricas.\n",
    "# TF-IDF (Term Frequency-Inverse Document Frequency) es una técnica común para asignar un peso a cada palabra en un documento dentro de una colección de documentos (el corpus).\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Inicializa el vectorizador TF-IDF.\n",
    "# max_features=5000 limita el número de características (palabras únicas) a las 5000 más frecuentes, lo que ayuda a reducir la dimensionalidad y el ruido. Este parámetro puede ajustarse.\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train) # Aprende el vocabulario del conjunto de entrenamiento y transforma los datos de entrenamiento en una matriz TF-IDF.\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test) # Utiliza el vocabulario aprendido del conjunto de entrenamiento para transformar los datos de prueba en la misma representación TF-IDF. Es importante usar el mismo vectorizador para ambos conjuntos para asegurar la consistencia de las características.\n",
    "\n",
    "print(\"\\nForma de la matriz TF-IDF para el conjunto de entrenamiento:\", X_train_tfidf.shape) # Muestra la dimensión de la matriz TF-IDF del conjunto de entrenamiento (número de muestras x número de características).\n",
    "print(\"Forma de la matriz TF-IDF para el conjunto de prueba:\", X_test_tfidf.shape) # Muestra la dimensión de la matriz TF-IDF del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b5dac227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelado: Regresión Logística\n",
    "# Se elige el modelo de Regresión Logística, un algoritmo lineal que es eficaz para problemas de clasificación de texto.\n",
    "logistic_regression_model = LogisticRegression(random_state=42) # Inicializa el modelo de Regresión Logística. random_state asegura la reproducibilidad del entrenamiento.\n",
    "logistic_regression_model.fit(X_train_tfidf, y_train) # Entrena el modelo utilizando la representación TF-IDF del conjunto de entrenamiento y las etiquetas correspondientes.\n",
    "y_pred_lr = logistic_regression_model.predict(X_test_tfidf) # Realiza predicciones sobre el conjunto de prueba transformado con TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a3230acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados del modelo de Regresión Logística:\n",
      "Precisión: 0.9300\n",
      "\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3515\n",
      "           1       0.92      0.94      0.93      3316\n",
      "\n",
      "    accuracy                           0.93      6831\n",
      "   macro avg       0.93      0.93      0.93      6831\n",
      "weighted avg       0.93      0.93      0.93      6831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "# Se evalúa el rendimiento del modelo utilizando métricas comunes para la clasificación.\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr) # Calcula la precisión, que es el porcentaje de predicciones correctas.\n",
    "report_lr = classification_report(y_test, y_pred_lr) # Genera un informe de clasificación que incluye precisión, recall, F1-score y soporte para cada clase.\n",
    "\n",
    "print(\"\\nResultados del modelo de Regresión Logística:\")\n",
    "print(f\"Precisión: {accuracy_lr:.4f}\") # Muestra la precisión con cuatro decimales.\n",
    "print(\"\\nReporte de Clasificación:\\n\", report_lr) # Muestra el informe de clasificación completo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef022560",
   "metadata": {},
   "source": [
    "### Análisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7154f9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de puntaje de sentimiento:\n",
      "                                                text  sentiment_score\n",
      "0  donald trump sends out embarrassing new year‚s...          -0.7096\n",
      "1  drunk bragging trump staffer started russian c...          -0.3400\n",
      "2  sheriff david clarke becomes an internet joke ...          -0.2960\n",
      "3  trump is so obsessed he even has obama‚s name ...          -0.3052\n",
      "4  pope francis just called out donald trump duri...           0.0000\n"
     ]
    }
   ],
   "source": [
    "# Esta sección implementa un análisis de sentimiento básico utilizando la librería VADER (Valence Aware Dictionary and sEntiment Reasoner),\n",
    "# que está específicamente sintonizada para el sentimiento expresado en las redes sociales.\n",
    "try:\n",
    "    SentimentIntensityAnalyzer() # Intenta inicializar el analizador de sentimiento VADER.\n",
    "except LookupError:\n",
    "    print(\"Descargando léxico VADER...\")\n",
    "    nltk.download('vader_lexicon') # Descarga el léxico VADER si no se encuentra.\n",
    "    print(\"Léxico VADER descargado.\")\n",
    "\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer() # Inicializa el analizador de sentimiento.\n",
    "df['sentiment_score'] = df['text'].apply(lambda text: sentiment_analyzer.polarity_scores(text)['compound'])\n",
    "# Aplica el analizador de sentimiento a cada texto en la columna 'text'.\n",
    "# polarity_scores devuelve un diccionario con las puntuaciones de sentimiento negativo, neutral, positivo y compuesto.\n",
    "# Se extrae la puntuación 'compound', que es una métrica normalizada y ponderada del sentimiento general.\n",
    "print(\"\\nEjemplo de puntaje de sentimiento:\")\n",
    "print(df[['text', 'sentiment_score']].head()) # Muestra las primeras filas con el texto original y su puntuación de sentimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd0019",
   "metadata": {},
   "source": [
    "### Testear con archivo testing_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8d171bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del testing_data:\n",
      "  marker                                               text\n",
      "0      2  copycat muslim terrorist arrested with assault...\n",
      "1      2  wow! chicago protester caught on camera admits...\n",
      "2      2   germany's fdp look to fill schaeuble's big shoes\n",
      "3      2  mi school sends welcome back packet warning ki...\n",
      "4      2  u.n. seeks 'massive' aid boost amid rohingya '...\n",
      "\n",
      "Información del testing_data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9984 entries, 0 to 9983\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   marker  9984 non-null   object\n",
      " 1   text    9984 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 156.1+ KB\n",
      "None\n",
      "\n",
      "Texto preprocesado del testing_data (ejemplo):\n",
      "                                                text  \\\n",
      "0  copycat muslim terrorist arrested with assault...   \n",
      "1  wow! chicago protester caught on camera admits...   \n",
      "2   germany's fdp look to fill schaeuble's big shoes   \n",
      "3  mi school sends welcome back packet warning ki...   \n",
      "4  u.n. seeks 'massive' aid boost amid rohingya '...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0   copycat muslim terrorist arrested assault weapon  \n",
      "1  wow chicago protester caught camera admits vio...  \n",
      "2          germany fdp look fill schaeubles big shoe  \n",
      "3  mi school sends welcome back packet warning ki...  \n",
      "4  un seek massive aid boost amid rohingya emerge...  \n"
     ]
    }
   ],
   "source": [
    "# Esta sección carga un nuevo conjunto de datos de prueba y aplica el mismo preprocesamiento y el modelo entrenado para realizar predicciones en datos nuevos.\n",
    "testing_file_path = 'data/testing_data.csv' # Define la ruta al archivo de prueba.\n",
    "df_test = pd.read_csv(testing_file_path, header=None, names=['marker', 'text'], sep='\\t')\n",
    "# Carga el archivo de prueba de manera similar al archivo de entrenamiento, con columnas 'marker' y 'text'.\n",
    "\n",
    "print(\"Primeras filas del testing_data:\")\n",
    "print(df_test.head()) # Muestra las primeras filas del DataFrame de prueba.\n",
    "print(\"\\nInformación del testing_data:\")\n",
    "print(df_test.info()) # Proporciona información sobre el DataFrame de prueba.\n",
    "df_test['cleaned_text'] = df_test['text'].apply(clean_text) # Aplica la misma función de limpieza de texto al conjunto de datos de prueba.\n",
    "print(\"\\nTexto preprocesado del testing_data (ejemplo):\")\n",
    "print(df_test[['text', 'cleaned_text']].head()) # Muestra un ejemplo del texto preprocesado en el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "06bf303c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma de la matriz TF-IDF para el testing_data: (9984, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_test_new_tfidf = tfidf_vectorizer.transform(df_test['cleaned_text'])\n",
    "# Utiliza el vectorizador TF-IDF *entrenado* previamente con los datos de entrenamiento para transformar el texto preprocesado del conjunto de datos de prueba en la misma representación numérica.\n",
    "# ¡Es crucial usar el mismo vectorizador para asegurar la consistencia de las características!\n",
    "print(\"\\nForma de la matriz TF-IDF para el testing_data:\", X_test_new_tfidf.shape) # Muestra la forma de la matriz TF-IDF para el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a2cdf01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicciones del modelo de Regresión Logística para testing_data:\n",
      "[0 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_new_lr = logistic_regression_model.predict(X_test_new_tfidf)\n",
    "# Utiliza el modelo de Regresión Logística *entrenado* previamente para hacer predicciones sobre los datos de prueba vectorizados.\n",
    "print(\"\\nPredicciones del modelo de Regresión Logística para testing_data:\")\n",
    "print(y_pred_new_lr) # Muestra las predicciones del modelo para el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77f3c19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Puntajes de sentimiento para testing_data (ejemplo):\n",
      "                                                text  sentiment_score\n",
      "0  copycat muslim terrorist arrested with assault...          -0.9382\n",
      "1  wow! chicago protester caught on camera admits...           0.3382\n",
      "2   germany's fdp look to fill schaeuble's big shoes           0.0000\n",
      "3  mi school sends welcome back packet warning ki...           0.1531\n",
      "4  u.n. seeks 'massive' aid boost amid rohingya '...          -0.3612\n"
     ]
    }
   ],
   "source": [
    "df_test['sentiment_score'] = df_test['text'].apply(lambda text: sentiment_analyzer.polarity_scores(text)['compound'])\n",
    "# Aplica el análisis de sentimiento al conjunto de datos de prueba de la misma manera que se hizo con el conjunto de entrenamiento.\n",
    "print(\"\\nPuntajes de sentimiento para testing_data (ejemplo):\")\n",
    "print(df_test[['text', 'sentiment_score']].head()) # Muestra un ejemplo de los puntajes de sentimiento para el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff489ce8",
   "metadata": {},
   "source": [
    "### Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "60bfd467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: fake_news_model.joblib\n",
      "Vectorizador guardado en: tfidf_vectorizer.joblib\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model_filename = 'fake_news_model.joblib' # Define el nombre del archivo donde se guardará el modelo.\n",
    "joblib.dump(logistic_regression_model, model_filename) # Guarda el objeto del modelo de Regresión Logística en el archivo especificado.\n",
    "print(f\"Modelo guardado en: {model_filename}\") # Informa al usuario de que el modelo se ha guardado.\n",
    "\n",
    "# Guardar el vectorizador entrenado\n",
    "vectorizer_filename = 'tfidf_vectorizer.joblib' # Define el nombre del archivo donde se guardará el vectorizador.\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_filename) # Guarda el objeto del vectorizador TF-IDF en el archivo especificado.\n",
    "print(f\"Vectorizador guardado en: {vectorizer_filename}\") # Informa al usuario de que el vectorizador se ha guardado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyectoNLP-iyaReRwX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
